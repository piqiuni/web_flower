# Behavior 环境

## 基础赛道
### 传感器数据

摄像头
RGBD
![[Pasted image 20251117191259.png]]

### 机器人定位信息
https://github.com/luigifreda/pyslam
视觉里程计
输入 RGBD image -> 输出 Odometry
![[Pasted image 20251117202609.png]]

 
## 特权赛道
机器人位姿
目标物体位姿

![[Pasted image 20251117191352.png]]


# SG-NAV
![[Pasted image 20251117152013.png]]
![[test.gif]]


**使用模型：**
groundedsam——文本-图像分割匹配
glip——目标检测
llama3.2-vision——关联构建、评分
# VLFM


![[Pasted image 20251117153635.png]]
**使用模型：**
MOBILE_SAM——分割
GroundingDINO——文本-图像分割匹配
BLIP2——
YOLOV7——目标检测

底层 Frontier map + point nav动作生成



**对基础赛道：**
输入：VO+目标引导
输出：底盘3维动作

**对特权赛道：**
输入：目标相对坐标
输出：底盘动作